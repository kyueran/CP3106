{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CenterTrack-Tracking-Objects-as-Points.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyueran/CP3106/blob/main/CenterTrack-Tracking-Objects-as-Points.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPw8WGdCfyk8"
      },
      "source": [
        "# CenterTrack - Tracking Objects as Points\n",
        "Simultaneous object detection and tracking using center points:\n",
        "<img src=\"https://github.com/xingyizhou/CenterTrack/raw/master/readme/fig2.png\">\n",
        "\n",
        "**Original code :** [CenterTrack](https://github.com/xingyizhou/CenterTrack) by [Xingyi Zhou](https://github.com/xingyizhou)\n",
        "\n",
        "**[Tracking Objects as Points](http://arxiv.org/abs/2004.01177)**,\n",
        "\n",
        "Xingyi Zhou, Vladlen Koltun, Philipp Krähenbühl,\n",
        "\n",
        "*arXiv technical report [(arXiv 2004.01177)](http://arxiv.org/abs/2004.01177)*\n",
        "\n",
        "**Citation**\n",
        "```\n",
        "@article{zhou2020tracking,\n",
        "  title={Tracking Objects as Points},\n",
        "  author={Zhou, Xingyi and Koltun, Vladlen and Kr{\\\"a}henb{\\\"u}hl, Philipp},\n",
        "  journal={ECCV},\n",
        "  year={2020}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMWkS8jt0Cjf",
        "outputId": "d83417b0-c23f-4a57-9a12-601cdb4f8d46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! nvidia-smi\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr  8 16:44:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk7mjfbqYvdS"
      },
      "source": [
        "## Installation\n",
        "1. Install PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CJ6c5Y4psPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a5c787-b51e-432e-abed-361682588359"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruJju8S9r7o8",
        "outputId": "39859f25-4183-42c3-dc75-4495cd7581c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install torch==1.4.0 torchvision==0.5.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.4.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjqXYyuhIJH7"
      },
      "source": [
        "2. Install [COCOAPI](https://github.com/cocodataset/cocoapi):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wroZnDoPIOcp",
        "outputId": "0b0ff854-0dec-4e33-f122-6206408701a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install cython; pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-ap8srq6_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ap8srq6_\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools==2.0) (75.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.11/dist-packages (from pycocotools==2.0) (3.0.12)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools==2.0) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.17.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp311-cp311-linux_x86_64.whl size=395987 sha256=998621e133ebe62b6762318bb9573dfb3126101c0a4ab2a4b76d7d1c3b916465\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-__ayvhhz/wheels/6d/69/75/358c50a37672dfda8d74ba3b30ec49fb75d52f7c081886d503\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.8\n",
            "    Uninstalling pycocotools-2.0.8:\n",
            "      Successfully uninstalled pycocotools-2.0.8\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ucy9RTJIZ0V"
      },
      "source": [
        "3. Clone this repo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF_X5OgX2Qvz",
        "outputId": "836a54db-b3ec-4d94-9368-bc271d039b22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "CenterTrack_ROOT=\"CenterTrack\"\n",
        "! git clone --recursive https://github.com/xingyizhou/CenterTrack $CenterTrack_ROOT\n",
        "%cd CenterTrack"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CenterTrack'...\n",
            "remote: Enumerating objects: 293, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 293 (delta 1), reused 2 (delta 0), pack-reused 285 (from 1)\u001b[K\n",
            "Receiving objects: 100% (293/293), 15.02 MiB | 16.93 MiB/s, done.\n",
            "Resolving deltas: 100% (110/110), done.\n",
            "/content/CenterTrack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvnAkG0jJgFZ"
      },
      "source": [
        "You can manually install the [submodules](https://github.com/xingyizhou/CenterTrack/blob/master/.gitmodules) if you forget --recursive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQJPHZVQIib3"
      },
      "source": [
        "4. Install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFIuWq-x2VrZ",
        "outputId": "294eb1c6-340a-48a5-d987-9dbbd845b081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install -r requirements.txt\n",
        "! apt-get install libx264-dev"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (4.11.0.86)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.60.0)\n",
            "Collecting progress (from -r requirements.txt (line 4))\n",
            "  Downloading progress-1.6.tar.gz (7.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.14.1)\n",
            "Collecting pyquaternion (from -r requirements.txt (line 8))\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting nuscenes-devkit (from -r requirements.txt (line 9))\n",
            "  Downloading nuscenes_devkit-1.1.11-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (6.0.2)\n",
            "Collecting motmetrics (from -r requirements.txt (line 11))\n",
            "  Downloading motmetrics-1.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==0.22.2 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0rc1, 1.2.0, 1.2.1, 1.2.2, 1.3.0rc1, 1.3.0, 1.3.1, 1.3.2, 1.4.0rc1, 1.4.0, 1.4.1.post1, 1.4.2, 1.5.0rc1, 1.5.0, 1.5.1, 1.5.2, 1.6.0rc1, 1.6.0, 1.6.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for scikit-learn==0.22.2\u001b[0m\u001b[31m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libx264-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.\n",
            "Need to get 659 kB of archives.\n",
            "After this operation, 2,827 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libx264-dev amd64 2:0.163.3060+git5db6aa6-2build1 [659 kB]\n",
            "Fetched 659 kB in 1s (598 kB/s)\n",
            "Selecting previously unselected package libx264-dev:amd64.\n",
            "(Reading database ... 126213 files and directories currently installed.)\n",
            "Preparing to unpack .../libx264-dev_2%3a0.163.3060+git5db6aa6-2build1_amd64.deb ...\n",
            "Unpacking libx264-dev:amd64 (2:0.163.3060+git5db6aa6-2build1) ...\n",
            "Setting up libx264-dev:amd64 (2:0.163.3060+git5db6aa6-2build1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2nytZeG-TawS",
        "outputId": "d4594e56-7524-4980-b97f-a16e2a6610a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKJ6tH2P23jN",
        "outputId": "97fae1e4-fdeb-4c24-acba-0e98cdd535a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ls src/lib/model/networks/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbackbones\u001b[0m/  base_model.py  dla.py  dlav0.py  generic_network.py  \u001b[01;34mnecks\u001b[0m/  resdcn.py  resnet.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDiYoRH7oM5x"
      },
      "source": [
        "#%rm -r src/lib/model/networks/DCNv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7-8pXOBJu8G"
      },
      "source": [
        "5. Compile deformable convolutional (from DCNv2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCylGnMy2Xkj",
        "outputId": "295e3388-b3ee-46a2-8a71-683476f0a917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        }
      },
      "source": [
        "# clone if it is not automatically downloaded by `--recursive`.\n",
        "%%shell\n",
        "\n",
        "cd src/lib/model/networks/\n",
        "git clone https://github.com/CharlesShang/DCNv2/\n",
        "cd DCNv2/\n",
        "./make.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DCNv2'...\n",
            "remote: Enumerating objects: 214, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 214 (delta 64), reused 49 (delta 49), pack-reused 137 (from 1)\u001b[K\n",
            "Receiving objects: 100% (214/214), 1.40 MiB | 15.97 MiB/s, done.\n",
            "Resolving deltas: 100% (133/133), done.\n",
            "running build\n",
            "running build_ext\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:529: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "building '_ext' extension\n",
            "creating build/temp.linux-x86_64-cpython-311/content/CenterTrack/src/lib/model/networks/DCNv2/src/cpu\n",
            "creating build/temp.linux-x86_64-cpython-311/content/CenterTrack/src/lib/model/networks/DCNv2/src/cuda\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DWITH_CUDA -I/content/CenterTrack/src/lib/model/networks/DCNv2/src -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c /content/CenterTrack/src/lib/model/networks/DCNv2/src/cpu/dcn_v2_cpu.cpp -o build/temp.linux-x86_64-cpython-311/content/CenterTrack/src/lib/model/networks/DCNv2/src/cpu/dcn_v2_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "\u001b[01m\u001b[K/content/CenterTrack/src/lib/model/networks/DCNv2/src/cpu/dcn_v2_cpu.cpp:7:10:\u001b[m\u001b[K \u001b[01;31m\u001b[Kfatal error: \u001b[m\u001b[KTH/TH.h: No such file or directory\n",
            "    7 | #include \u001b[01;31m\u001b[K<TH/TH.h>\u001b[m\u001b[K\n",
            "      |          \u001b[01;31m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "compilation terminated.\n",
            "error: command '/usr/bin/x86_64-linux-gnu-g++' failed with exit code 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '\ncd src/lib/model/networks/\ngit clone https://github.com/CharlesShang/DCNv2/  \ncd DCNv2/\n./make.sh\n' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dc93afd31b03>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\ncd src/lib/model/networks/\\ngit clone https://github.com/CharlesShang/DCNv2/  \\ncd DCNv2/\\n./make.sh\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '\ncd src/lib/model/networks/\ngit clone https://github.com/CharlesShang/DCNv2/  \ncd DCNv2/\n./make.sh\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t1BrZh-KAJ1"
      },
      "source": [
        "6. Download pertained models for [monocular 3D tracking](https://drive.google.com/open?id=1e8zR1m1QMJne-Tjp-2iY_o81hn2CiQRt), [80-category tracking](https://drive.google.com/open?id=1tJCEJmdtYIh8VuN8CClGNws3YO7QGd40), or [pose tracking](https://drive.google.com/open?id=1tJCEJmdtYIh8VuN8CClGNws3YO7QGd40) and move them to\n",
        "`$CenterTrack_ROOT/models/`.\n",
        "\n",
        "  More models can be found in [Model zoo](https://github.com/xingyizhou/CenterTrack/blob/master/readme/MODEL_ZOO.md)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5mlF2KXZddE"
      },
      "source": [
        "%mkdir models\n",
        "#! gdown --id 1e8zR1m1QMJne-Tjp-2iY_o81hn2CiQRt -O models/nuScenes_3Dtracking.pth\n",
        "#! gdown --id 1tJCEJmdtYIh8VuN8CClGNws3YO7QGd40 -O models/coco_tracking.pth\n",
        "#! gdown --id 1H0YvFYCOIZ06EzAkC2NxECNQGXxK27hH -O models/coco_pose_tracking.pth\n",
        "! gdown --id 1sf1bWJ1LutwQ_wp176nd2Y3HII9WeFf0 -O models/mot17_half.pth\n",
        "! gdown --id 1h_8Ts11rf0GQ4_n6FgmCeBuFcWrRjJfa -O models/mot17_fulltrain.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdHblfZC7wpX"
      },
      "source": [
        "#!pip install youtube-dl\n",
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "YOUTUBE_ID = 'MNn9qKG2UFI'   # car\n",
        "#YOUTUBE_ID = 'MNn9qKG2UFI'\n",
        "#YOUTUBE_ID = '2bKXv_XviFc'    # pedestrian\n",
        "\n",
        "YouTubeVideo(YOUTUBE_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF9KFFql7xkX"
      },
      "source": [
        "#! rm -rf youtube.mp4\n",
        "# download the youtube with the given ID\n",
        "! youtube-dl -f 'bestvideo[ext=mp4]' --output \"youtube2.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
        "# cut the first 5 seconds\n",
        "#! ffmpeg -y -loglevel info -i youtube2.mp4 -t 20 pedestrian.avi\n",
        "! ffmpeg -y -loglevel info -i youtube.mp4 -t 20 road_traffic.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn0cPU8RfXbo"
      },
      "source": [
        "## Use CenterTrack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRsTsPCd-YAO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3d64c6d-aecf-42fb-c684-171f99e81f62"
      },
      "source": [
        "%cd src/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CenterTrack/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkGUyAR5NPyA"
      },
      "source": [
        "**Note:**\n",
        "1. replace \"cv2.imshow\" in function show_all_image in \"debugger.py(/src/lib/utils/)\" with \"pass\"\n",
        "2. comment out  \"cv2.imshow\" at line 80 in \"demo.py\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_eepSVd8VIa"
      },
      "source": [
        "Video clip from the [nuScenes dataset](https://www.nuscenes.org/?externalData=all&mapData=all&modalities=Any) in `videos/nuscenes_mini.mp4`. To test monocular 3D tracking on this video, run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzdHGbh-8DPi"
      },
      "source": [
        "! python demo.py tracking,ddd --load_model ../models/nuScenes_3Dtracking.pth --dataset nuscenes --pre_hm --track_thresh 0.1 --demo ../videos/nuscenes_mini.mp4 --test_focal_length 633 --save_video --video_h 480 --video_w 720 --debug 2\n",
        "#! python demo.py tracking,ddd --load_model ../models/nuScenes_3Dtracking.pth --dataset nuscenes --pre_hm --track_thresh 0.1 --demo road_traffic.avi --save_video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vZilmH_88bH"
      },
      "source": [
        "You will need to specify test_focal_length for monocular 3D tracking demo to convert the image coordinate system back to 3D. The value 633 is half of a typical focal length (~1266) in nuScenes dataset in input resolution 1600x900. The mini demo video is in an input resolution of 800x448, so we need to use a half focal length. You don't need to set the test_focal_length when testing on the original nuScenes data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra4B0CzB9XEx"
      },
      "source": [
        "Similarly, for 80-category tracking on images/ video, run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7B_4SKd1_n5"
      },
      "source": [
        "! python demo.py tracking --load_model ../models/coco_tracking.pth --demo road_traffic.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfs1XUiW9fcn"
      },
      "source": [
        "If you want to test with person tracking models, you need to add --num_class 1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5KPZwaT9gGR"
      },
      "source": [
        "! python demo.py tracking --load_model ../models/mot17_half.pth --num_class 1 --demo pedestrian.avi --save_video\n",
        "#! python demo.py tracking --load_model ../models/mot17_fulltrain.pth --num_class 1 --demo pedestrian.avi --save_video --debug 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSMzMJXC96IP"
      },
      "source": [
        "You can add --debug 2 to visualize the heatmap and offset predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAwdEdFT94W5"
      },
      "source": [
        "! python demo.py tracking --load_model ../models/mot17_half.pth --num_class 1 --debug 2 --demo video.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TF8AOxtQ9lTy"
      },
      "source": [
        "For monocular 3D tracking, run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vnmvi9yL9nvo"
      },
      "source": [
        "! python demo.py tracking,ddd --demo ../road_traffic.mp4 --load_model ../models/coco_tracking.pth --save_video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6r6ZlYs9ud-"
      },
      "source": [
        "Similarly, for pose tracking, run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyzdY5ju9u7k"
      },
      "source": [
        "! python demo.py tracking,multi_pose --load_model ../models/coco_pose.pth --demo video.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjqq06mMem3Q"
      },
      "source": [
        "## Training on custom dataset\n",
        "If you want to train CenterTrack on your own dataset, you can use `--dataset custom` and manually specify the annotation file, image path, input resolutions, and number of categories. You still need to create the annotation files in COCO format (referring to the many `convert_X_to_coco.py` examples in tools). For example, you can use the following command to train on our [mot17 experiment](https://github.com/xingyizhou/CenterTrack/blob/master/experiments/mot17_half_sc.sh) without using the pre-defined mot dataset file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89uylqque2lG"
      },
      "source": [
        "! python main.py tracking --exp_id mot17_half_sc --dataset custom --custom_dataset_ann_path ../data/mot17/annotations/train_half.json --custom_dataset_img_path ../data/mot17/train/ --input_h 544 --input_w 960 --num_classes 1 --pre_hm --ltrb_amodal --same_aug --hm_disturb 0.05 --lost_disturb 0.4 --fp_disturb 0.1 --gpus 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u84xB-4YciO-"
      },
      "source": [
        "## Benchmark Evaluation and Training\n",
        "After installation, follow the instructions in [DATA.md](https://github.com/xingyizhou/CenterTrack/blob/master/readme/DATA.md) to setup the datasets. Then check [GETTING_STARTED.md](https://github.com/xingyizhou/CenterTrack/blob/master/readme/GETTING_STARTED.md) to reproduce the results in the paper. We provide scripts for all the experiments in the [experiments folder](https://github.com/xingyizhou/CenterTrack/blob/master/experiments)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uudcC2xMdO4t"
      },
      "source": [
        "### **Benchmark evaluation**\n",
        "First, download the models you want to evaluate from our model zoo and put them in CenterTrack_ROOT/models/.\n",
        "\n",
        "**MOT17**\n",
        "\n",
        "To test the tracking performance on MOT17 with our pretrained model, run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0SiynR5dRaM"
      },
      "source": [
        "! python test.py tracking --exp_id mot17_half --dataset mot --dataset_version 17halfval --pre_hm --ltrb_amodal --track_thresh 0.4 --pre_thresh 0.5 --load_model ../models/mot17_half.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drou-llkdgiH"
      },
      "source": [
        "This will give a MOTA of `66.1` if set up correctly. `--pre_hm` is to enable the input heatmap. `--ltrb_amodal` is to use the left, top, right, bottom bounding box representation to enable detecting out-of-image bounding box (We observed this is important for MOT datasets). And `--track_thresh` and `--pre_thresh` are the score threshold for predicting a bounding box ($\\theta$ in the paper) and feeding the heatmap to the next frame ($\\tau$ in the paper), respectively.\n",
        "\n",
        "To test with public detection, run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFOAtnMzdhXT"
      },
      "source": [
        "! python test.py tracking --exp_id mot17_half_public --dataset mot --dataset_version 17halfval --pre_hm --ltrb_amodal --track_thresh 0.4 --pre_thresh 0.5 --load_model ../models/mot17_half.pth --public_det --load_results ../data/mot17/results/val_half_det.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzzCMMn3d4eo"
      },
      "source": [
        "The expected MOTA is `63.1`.\n",
        "\n",
        "To test on the test set, run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0J273JgeNVw"
      },
      "source": [
        "### Training\n",
        "We have packed all the training scripts in the [experiments folder](https://github.com/xingyizhou/CenterTrack/blob/master/experiments). The experiment names correspond to the model name in the [model zoo](https://github.com/xingyizhou/CenterTrack/blob/master/experiments). The number of GPUs for each experiment can be found in the scripts and the model zoo. If the training is terminated before finishing, you can use the same command with `--resume` to resume training. It will found the latest model with the same `exp_id`. Some experiments rely on pretraining on another model. In this case, download the pretrained model from our model zoo or train that model first."
      ]
    }
  ]
}